{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some configs\n",
    "\n",
    "DATASET_ROOT = '/home/xy/research/dataset/OpportunityUCIDataset/dataset/RLA_dataset'\n",
    "NUM_TRAINING_SAMPLES = 557963\n",
    "BATCH_SIZE = 1\n",
    "BUFFER_SIZE = 100\n",
    "# pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[INFO] Data Input Pipeline\n"
    }
   ],
   "source": [
    "print ('[INFO] Data Input Pipeline')\n",
    "txt_list = os.listdir(DATASET_ROOT)\n",
    "train_txt = os.path.join(DATASET_ROOT,txt_list[0])\n",
    "val_txt = os.path.join(DATASET_ROOT,txt_list[1])\n",
    "total_txt = os.path.join(DATASET_ROOT,txt_list[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Reading:  /home/xy/research/dataset/OpportunityUCIDataset/dataset/RLA_dataset/RLA_total.txt\ntotal data shape: (676713, 13)\n"
    }
   ],
   "source": [
    "print('Reading: ', total_txt)\n",
    "total_dataset = np.loadtxt(total_txt)\n",
    "print ('total data shape:', total_dataset.shape)\n",
    "train_dataset = total_dataset[:NUM_TRAINING_SAMPLES,:]\n",
    "val_dataset = total_dataset[NUM_TRAINING_SAMPLES:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_dataset[:,:13]\n",
    "train_label = train_dataset[:,-1]\n",
    "val_data = val_dataset[:,:13]\n",
    "val_label = val_dataset[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(13, 557963)\n(557963,)\n"
    }
   ],
   "source": [
    "train_data = train_data.transpose()\n",
    "print (train_data.shape) #shape:(13,557963)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     0.2763\n1     0.6036\n2     0.5612\n3     0.4816\n4     0.4374\n5     0.4701\n6     0.4736\n7     0.6297\n8     0.3673\n9     0.6715\n10    0.8023\n11    0.4942\n12    0.1350\nName: 23, dtype: float64"
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "train_data = np.squeeze(train_data)\n",
    "df_train = pd.DataFrame(train_data)\n",
    "df_train.iloc[:,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(557963,)\n"
    }
   ],
   "source": [
    "def sliding_window(data,label,win_step,stride):\n",
    "    data_features, data_length = data.shape[0],data.shape[1]\n",
    "    label_length = label.shape[0] # 557963\n",
    "    for i in range (0,data_length+1,stride):\n",
    "        seq_input = np.zeros_like(13,24,12)\n",
    "        seq_target = np.zeros_like(24)\n",
    "\n",
    "for row in train_data:\n",
    "    pass\n",
    "print (row.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        0       1       2       3       4       5       6       7       8   \\\n0   0.2678  0.2649  0.2675  0.2582  0.2553  0.2532  0.2542  0.2447  0.2561   \n1   0.6541  0.6774  0.6114  0.5953  0.5923  0.5725  0.5840  0.6068  0.6189   \n2   0.5296  0.5643  0.5543  0.5551  0.5569  0.5739  0.5689  0.5633  0.5620   \n3   0.5042  0.4685  0.4484  0.4570  0.4629  0.4763  0.4931  0.4990  0.4998   \n4   0.4292  0.4342  0.4379  0.4403  0.4401  0.4335  0.4227  0.4210  0.4196   \n5   0.4823  0.4852  0.4790  0.4729  0.4708  0.4670  0.4611  0.4563  0.4555   \n6   0.4544  0.4550  0.4559  0.4579  0.4594  0.4612  0.4612  0.4600  0.4603   \n7   0.6068  0.6071  0.6120  0.6174  0.6215  0.6249  0.6256  0.6251  0.6234   \n8   0.3653  0.3659  0.3666  0.3677  0.3689  0.3698  0.3697  0.3691  0.3681   \n9   0.6094  0.6192  0.6289  0.6361  0.6412  0.6433  0.6422  0.6397  0.6371   \n10  0.8090  0.8079  0.8059  0.8054  0.8049  0.8044  0.8039  0.8039  0.8044   \n11  0.4553  0.4579  0.4663  0.4737  0.4805  0.4847  0.4853  0.4853  0.4842   \n12  0.1200  0.1220  0.1230  0.1245  0.1255  0.1255  0.1250  0.1240  0.1235   \n\n        9   ...      14      15      16      17      18      19      20  \\\n0   0.2604  ...  0.2763  0.2771  0.2768  0.2760  0.2739  0.2731  0.2675   \n1   0.6237  ...  0.6243  0.6170  0.6154  0.6135  0.6141  0.6162  0.5988   \n2   0.5638  ...  0.5779  0.5731  0.5699  0.5718  0.5675  0.5566  0.5638   \n3   0.4966  ...  0.4853  0.4850  0.4847  0.4830  0.4840  0.4862  0.4812   \n4   0.4247  ...  0.4290  0.4290  0.4285  0.4290  0.4280  0.4303  0.4322   \n5   0.4567  ...  0.4704  0.4743  0.4761  0.4756  0.4755  0.4796  0.4775   \n6   0.4597  ...  0.4638  0.4641  0.4653  0.4659  0.4668  0.4683  0.4694   \n7   0.6228  ...  0.6238  0.6247  0.6256  0.6262  0.6266  0.6275  0.6279   \n8   0.3672  ...  0.3651  0.3651  0.3653  0.3653  0.3656  0.3659  0.3661   \n9   0.6361  ...  0.6438  0.6468  0.6504  0.6540  0.6576  0.6607  0.6643   \n10  0.8044  ...  0.8034  0.8029  0.8023  0.8018  0.8013  0.8013  0.8013   \n11  0.4842  ...  0.4858  0.4863  0.4868  0.4879  0.4884  0.4879  0.4895   \n12  0.1230  ...  0.1250  0.1260  0.1270  0.1275  0.1285  0.1300  0.1315   \n\n        21      22      23  \n0   0.2704  0.2739  0.2763  \n1   0.6028  0.6114  0.6036  \n2   0.5649  0.5620  0.5612  \n3   0.4833  0.4860  0.4816  \n4   0.4333  0.4349  0.4374  \n5   0.4731  0.4744  0.4701  \n6   0.4709  0.4721  0.4736  \n7   0.6290  0.6294  0.6297  \n8   0.3662  0.3670  0.3673  \n9   0.6663  0.6689  0.6715  \n10  0.8013  0.8018  0.8023  \n11  0.4911  0.4916  0.4942  \n12  0.1325  0.1340  0.1350  \n\n[13 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.2678</td>\n      <td>0.2649</td>\n      <td>0.2675</td>\n      <td>0.2582</td>\n      <td>0.2553</td>\n      <td>0.2532</td>\n      <td>0.2542</td>\n      <td>0.2447</td>\n      <td>0.2561</td>\n      <td>0.2604</td>\n      <td>...</td>\n      <td>0.2763</td>\n      <td>0.2771</td>\n      <td>0.2768</td>\n      <td>0.2760</td>\n      <td>0.2739</td>\n      <td>0.2731</td>\n      <td>0.2675</td>\n      <td>0.2704</td>\n      <td>0.2739</td>\n      <td>0.2763</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.6541</td>\n      <td>0.6774</td>\n      <td>0.6114</td>\n      <td>0.5953</td>\n      <td>0.5923</td>\n      <td>0.5725</td>\n      <td>0.5840</td>\n      <td>0.6068</td>\n      <td>0.6189</td>\n      <td>0.6237</td>\n      <td>...</td>\n      <td>0.6243</td>\n      <td>0.6170</td>\n      <td>0.6154</td>\n      <td>0.6135</td>\n      <td>0.6141</td>\n      <td>0.6162</td>\n      <td>0.5988</td>\n      <td>0.6028</td>\n      <td>0.6114</td>\n      <td>0.6036</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5296</td>\n      <td>0.5643</td>\n      <td>0.5543</td>\n      <td>0.5551</td>\n      <td>0.5569</td>\n      <td>0.5739</td>\n      <td>0.5689</td>\n      <td>0.5633</td>\n      <td>0.5620</td>\n      <td>0.5638</td>\n      <td>...</td>\n      <td>0.5779</td>\n      <td>0.5731</td>\n      <td>0.5699</td>\n      <td>0.5718</td>\n      <td>0.5675</td>\n      <td>0.5566</td>\n      <td>0.5638</td>\n      <td>0.5649</td>\n      <td>0.5620</td>\n      <td>0.5612</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5042</td>\n      <td>0.4685</td>\n      <td>0.4484</td>\n      <td>0.4570</td>\n      <td>0.4629</td>\n      <td>0.4763</td>\n      <td>0.4931</td>\n      <td>0.4990</td>\n      <td>0.4998</td>\n      <td>0.4966</td>\n      <td>...</td>\n      <td>0.4853</td>\n      <td>0.4850</td>\n      <td>0.4847</td>\n      <td>0.4830</td>\n      <td>0.4840</td>\n      <td>0.4862</td>\n      <td>0.4812</td>\n      <td>0.4833</td>\n      <td>0.4860</td>\n      <td>0.4816</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.4292</td>\n      <td>0.4342</td>\n      <td>0.4379</td>\n      <td>0.4403</td>\n      <td>0.4401</td>\n      <td>0.4335</td>\n      <td>0.4227</td>\n      <td>0.4210</td>\n      <td>0.4196</td>\n      <td>0.4247</td>\n      <td>...</td>\n      <td>0.4290</td>\n      <td>0.4290</td>\n      <td>0.4285</td>\n      <td>0.4290</td>\n      <td>0.4280</td>\n      <td>0.4303</td>\n      <td>0.4322</td>\n      <td>0.4333</td>\n      <td>0.4349</td>\n      <td>0.4374</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.4823</td>\n      <td>0.4852</td>\n      <td>0.4790</td>\n      <td>0.4729</td>\n      <td>0.4708</td>\n      <td>0.4670</td>\n      <td>0.4611</td>\n      <td>0.4563</td>\n      <td>0.4555</td>\n      <td>0.4567</td>\n      <td>...</td>\n      <td>0.4704</td>\n      <td>0.4743</td>\n      <td>0.4761</td>\n      <td>0.4756</td>\n      <td>0.4755</td>\n      <td>0.4796</td>\n      <td>0.4775</td>\n      <td>0.4731</td>\n      <td>0.4744</td>\n      <td>0.4701</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.4544</td>\n      <td>0.4550</td>\n      <td>0.4559</td>\n      <td>0.4579</td>\n      <td>0.4594</td>\n      <td>0.4612</td>\n      <td>0.4612</td>\n      <td>0.4600</td>\n      <td>0.4603</td>\n      <td>0.4597</td>\n      <td>...</td>\n      <td>0.4638</td>\n      <td>0.4641</td>\n      <td>0.4653</td>\n      <td>0.4659</td>\n      <td>0.4668</td>\n      <td>0.4683</td>\n      <td>0.4694</td>\n      <td>0.4709</td>\n      <td>0.4721</td>\n      <td>0.4736</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.6068</td>\n      <td>0.6071</td>\n      <td>0.6120</td>\n      <td>0.6174</td>\n      <td>0.6215</td>\n      <td>0.6249</td>\n      <td>0.6256</td>\n      <td>0.6251</td>\n      <td>0.6234</td>\n      <td>0.6228</td>\n      <td>...</td>\n      <td>0.6238</td>\n      <td>0.6247</td>\n      <td>0.6256</td>\n      <td>0.6262</td>\n      <td>0.6266</td>\n      <td>0.6275</td>\n      <td>0.6279</td>\n      <td>0.6290</td>\n      <td>0.6294</td>\n      <td>0.6297</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.3653</td>\n      <td>0.3659</td>\n      <td>0.3666</td>\n      <td>0.3677</td>\n      <td>0.3689</td>\n      <td>0.3698</td>\n      <td>0.3697</td>\n      <td>0.3691</td>\n      <td>0.3681</td>\n      <td>0.3672</td>\n      <td>...</td>\n      <td>0.3651</td>\n      <td>0.3651</td>\n      <td>0.3653</td>\n      <td>0.3653</td>\n      <td>0.3656</td>\n      <td>0.3659</td>\n      <td>0.3661</td>\n      <td>0.3662</td>\n      <td>0.3670</td>\n      <td>0.3673</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.6094</td>\n      <td>0.6192</td>\n      <td>0.6289</td>\n      <td>0.6361</td>\n      <td>0.6412</td>\n      <td>0.6433</td>\n      <td>0.6422</td>\n      <td>0.6397</td>\n      <td>0.6371</td>\n      <td>0.6361</td>\n      <td>...</td>\n      <td>0.6438</td>\n      <td>0.6468</td>\n      <td>0.6504</td>\n      <td>0.6540</td>\n      <td>0.6576</td>\n      <td>0.6607</td>\n      <td>0.6643</td>\n      <td>0.6663</td>\n      <td>0.6689</td>\n      <td>0.6715</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.8090</td>\n      <td>0.8079</td>\n      <td>0.8059</td>\n      <td>0.8054</td>\n      <td>0.8049</td>\n      <td>0.8044</td>\n      <td>0.8039</td>\n      <td>0.8039</td>\n      <td>0.8044</td>\n      <td>0.8044</td>\n      <td>...</td>\n      <td>0.8034</td>\n      <td>0.8029</td>\n      <td>0.8023</td>\n      <td>0.8018</td>\n      <td>0.8013</td>\n      <td>0.8013</td>\n      <td>0.8013</td>\n      <td>0.8013</td>\n      <td>0.8018</td>\n      <td>0.8023</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.4553</td>\n      <td>0.4579</td>\n      <td>0.4663</td>\n      <td>0.4737</td>\n      <td>0.4805</td>\n      <td>0.4847</td>\n      <td>0.4853</td>\n      <td>0.4853</td>\n      <td>0.4842</td>\n      <td>0.4842</td>\n      <td>...</td>\n      <td>0.4858</td>\n      <td>0.4863</td>\n      <td>0.4868</td>\n      <td>0.4879</td>\n      <td>0.4884</td>\n      <td>0.4879</td>\n      <td>0.4895</td>\n      <td>0.4911</td>\n      <td>0.4916</td>\n      <td>0.4942</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.1200</td>\n      <td>0.1220</td>\n      <td>0.1230</td>\n      <td>0.1245</td>\n      <td>0.1255</td>\n      <td>0.1255</td>\n      <td>0.1250</td>\n      <td>0.1240</td>\n      <td>0.1235</td>\n      <td>0.1230</td>\n      <td>...</td>\n      <td>0.1250</td>\n      <td>0.1260</td>\n      <td>0.1270</td>\n      <td>0.1275</td>\n      <td>0.1285</td>\n      <td>0.1300</td>\n      <td>0.1315</td>\n      <td>0.1325</td>\n      <td>0.1340</td>\n      <td>0.1350</td>\n    </tr>\n  </tbody>\n</table>\n<p>13 rows Ã— 24 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "sliding_data = train_data[:,:24]\n",
    "sliding_data = np.squeeze(sliding_data)\n",
    "\n",
    "df_see = pd.DataFrame(sliding_data)\n",
    "df_see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def window_stack(a, stepsize=1, width=3):\n",
    "    n = a.shape[0]\n",
    "    return np.hstack( a[i:1+n+i-width:stepsize] for i in range(0,width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1673889, 1)"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Dimensions 13 and 557963 are not compatible",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-6cb76e1a23e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtf_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    642\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \"\"\"\n\u001b[0;32m--> 644\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2792\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2793\u001b[0m       batch_dim.assert_is_compatible_with(tensor_shape.Dimension(\n\u001b[0;32m-> 2794\u001b[0;31m           tensor_shape.dimension_value(t.get_shape()[0])))\n\u001b[0m\u001b[1;32m   2795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2796\u001b[0m     variant_tensor = gen_dataset_ops.tensor_slice_dataset(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       raise ValueError(\"Dimensions %s and %s are not compatible\" %\n\u001b[0;32m--> 276\u001b[0;31m                        (self, other))\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions 13 and 557963 are not compatible"
     ]
    }
   ],
   "source": [
    "train_data = np.expand_dims(train_data,axis=2)\n",
    "val_data = np.expand_dims(val_data,axis=2)\n",
    "\n",
    "tf_train = tf.data.Dataset.from_tensor_slices((train_data,train_label))\n",
    "tf_val = tf.data.Dataset.from_tensor_slices((val_data,val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total label num: 557963\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5155    6794\n0.1250    1256\n0.7680    1213\n0.1265    1212\n0.1245    1160\n          ... \n0.9915      22\n0.9825      21\n1.0000      19\n0.9780      18\n0.0000      10\nLength: 2001, dtype: int64"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# Label imbalance \n",
    "s_train_label = pd.Series(train_label)\n",
    "print('Total label num:', s_train_label.count())\n",
    "s_train_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train = tf_train.shuffle(buffer_size=BUFFER_SIZE, seed=10101)\n",
    "tf_train = tf_train.batch(BATCH_SIZE)\n",
    "tf_train = tf_train.prefetch(1)\n",
    "tf_val = tf_val.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Data: tf.Tensor(\n[[[[0.6603]\n   [0.6897]\n   [0.6397]\n   [0.4215]\n   [0.289 ]\n   [0.3431]\n   [0.2267]\n   [0.7091]\n   [0.462 ]\n   [0.7166]\n   [0.3077]\n   [0.3147]\n   [0.129 ]]]], shape=(1, 1, 13, 1), dtype=float64)  shape: (1, 1, 13, 1)\nLabel: tf.Tensor([[0.129]], shape=(1, 1), dtype=float64)  shape: (1, 1)\n"
    }
   ],
   "source": [
    "for data,label in tf_train.take(1):\n",
    "    print('Data:',data, ' shape:',data.shape)\n",
    "    print('Label:',label, ' shape:',label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittf21condacb170c5154354f89a0768a21d002b8fb",
   "display_name": "Python 3.7.7 64-bit ('tf2.1': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}